#!/usr/bin/env python3
"""
ASCII Smuggling Detection Tool
Scans files for invisible unicode characters including tags, zero-width chars, etc.
"""

import argparse
import os
import sys
from pathlib import Path
from collections import defaultdict
import mimetypes
import json
import unicodedata


# Invisible Unicode Characters to detect
INVISIBLE_CHARS = {
    # Format controls and joiners
    '\u034F': 'COMBINING GRAPHEME JOINER',
    '\u061C': 'ARABIC LETTER MARK',
    '\u180E': 'MONGOLIAN VOWEL SEPARATOR',

    # Zero-width characters
    '\u200B': 'ZERO WIDTH SPACE',
    '\u200C': 'ZERO WIDTH NON-JOINER',
    '\u200D': 'ZERO WIDTH JOINER',
    '\u2060': 'WORD JOINER',

    # Directional/bidi marks
    '\u200E': 'LEFT-TO-RIGHT MARK',
    '\u200F': 'RIGHT-TO-LEFT MARK',
    '\u202A': 'LEFT-TO-RIGHT EMBEDDING',
    '\u202B': 'RIGHT-TO-LEFT EMBEDDING',
    '\u202C': 'POP DIRECTIONAL FORMATTING',
    '\u202D': 'LEFT-TO-RIGHT OVERRIDE',
    '\u202E': 'RIGHT-TO-LEFT OVERRIDE',
    '\u2066': 'LEFT-TO-RIGHT ISOLATE',
    '\u2067': 'RIGHT-TO-LEFT ISOLATE',
    '\u2068': 'FIRST STRONG ISOLATE',
    '\u2069': 'POP DIRECTIONAL ISOLATE',

    # Invisible operators (math/layout)
    '\u2061': 'FUNCTION APPLICATION',
    '\u2062': 'INVISIBLE TIMES',
    '\u2063': 'INVISIBLE SEPARATOR',
    '\u2064': 'INVISIBLE PLUS',

    # Deprecated format controls
    '\u206A': 'INHIBIT SYMMETRIC SWAPPING',
    '\u206B': 'ACTIVATE SYMMETRIC SWAPPING',
    '\u206C': 'INHIBIT ARABIC FORM SHAPING',
    '\u206D': 'ACTIVATE ARABIC FORM SHAPING',
    '\u206E': 'NATIONAL DIGIT SHAPES',
    '\u206F': 'NOMINAL DIGIT SHAPES',

    # BOM/ZWNBSP
    '\uFEFF': 'ZERO WIDTH NO-BREAK SPACE',

    # Variation selectors
    '\uFE00': 'VARIATION SELECTOR-1',
    '\uFE01': 'VARIATION SELECTOR-2',
    '\uFE02': 'VARIATION SELECTOR-3',
    '\uFE03': 'VARIATION SELECTOR-4',
    '\uFE04': 'VARIATION SELECTOR-5',
    '\uFE05': 'VARIATION SELECTOR-6',
    '\uFE06': 'VARIATION SELECTOR-7',
    '\uFE07': 'VARIATION SELECTOR-8',
    '\uFE08': 'VARIATION SELECTOR-9',
    '\uFE09': 'VARIATION SELECTOR-10',
    '\uFE0A': 'VARIATION SELECTOR-11',
    '\uFE0B': 'VARIATION SELECTOR-12',
    '\uFE0C': 'VARIATION SELECTOR-13',
    '\uFE0D': 'VARIATION SELECTOR-14',
    '\uFE0E': 'VARIATION SELECTOR-15',
    '\uFE0F': 'VARIATION SELECTOR-16',
}

# Optional confusable/suspicious spaces and fillers (off by default).
CONFUSABLE_SPACE_CHARS = {
    '\u00A0': 'NO-BREAK SPACE',
    '\u00AD': 'SOFT HYPHEN',
    '\u2000': 'EN QUAD',
    '\u2001': 'EM QUAD',
    '\u2002': 'EN SPACE',
    '\u2003': 'EM SPACE',
    '\u2004': 'THREE-PER-EM SPACE',
    '\u2005': 'FOUR-PER-EM SPACE',
    '\u2006': 'SIX-PER-EM SPACE',
    '\u2007': 'FIGURE SPACE',
    '\u2008': 'PUNCTUATION SPACE',
    '\u2009': 'THIN SPACE',
    '\u200A': 'HAIR SPACE',
    '\u202F': 'NARROW NO-BREAK SPACE',
    '\u205F': 'MEDIUM MATHEMATICAL SPACE',
    '\u2800': 'BRAILLE PATTERN BLANK',
    '\u3000': 'IDEOGRAPHIC SPACE',
    '\u3164': 'HANGUL FILLER',
    '\uFFA0': 'HALFWIDTH HANGUL FILLER',
}

# Unicode tag characters (U+E0000 to U+E007F)
# These can be decoded to ASCII
TAG_START = 0xE0000
TAG_END = 0xE007F
VARIATION_SELECTOR_SUPPLEMENT_START = 0xE0100
VARIATION_SELECTOR_SUPPLEMENT_END = 0xE01EF

# Category sets for summary breakdown
ZERO_WIDTH_CHARS = {'\u034F', '\u180E', '\u200B', '\u200C', '\u200D', '\u2060', '\uFEFF'}
DIRECTIONAL_MARKS = {'\u061C', '\u200E', '\u200F', '\u202A', '\u202B', '\u202C',
                     '\u202D', '\u202E', '\u2066', '\u2067', '\u2068', '\u2069'}
INVISIBLE_OPERATORS = {'\u2061', '\u2062', '\u2063', '\u2064'}
DEPRECATED_FORMAT_CONTROLS = {'\u206A', '\u206B', '\u206C', '\u206D', '\u206E', '\u206F'}
SPACE_LIKE_CHARS = {'\u00A0', '\u00AD', '\u2000', '\u2001', '\u2002', '\u2003', '\u2004',
                    '\u2005', '\u2006', '\u2007', '\u2008', '\u2009', '\u200A', '\u202F',
                    '\u205F', '\u2800', '\u3000', '\u3164', '\uFFA0'}
VARIATION_SELECTORS_BASIC = {chr(cp) for cp in range(0xFE00, 0xFE10)}
SKIP_CC_DEFAULT = {'\t', '\n', '\r'}
SKIP_ZS_DEFAULT = {' '}

# Directories to exclude from scanning (add more as needed)
EXCLUDED_DIRS = [
    '.git',
    # '.curated',  # Uncomment to exclude
    # 'node_modules',  # Uncomment to exclude
]


def is_unicode_tag(char):
    """Check if a character is a Unicode tag character."""
    code = ord(char)
    return TAG_START <= code <= TAG_END


def is_variation_selector_supplement(char):
    """Check if a character is in Variation Selectors Supplement."""
    code = ord(char)
    return VARIATION_SELECTOR_SUPPLEMENT_START <= code <= VARIATION_SELECTOR_SUPPLEMENT_END


def variation_selector_name(char):
    """Name for VS-17 through VS-256."""
    return f"VARIATION SELECTOR-{ord(char) - VARIATION_SELECTOR_SUPPLEMENT_START + 17}"


def control_char_name(char):
    """Readable label for control characters."""
    code = ord(char)
    try:
        return unicodedata.name(char)
    except ValueError:
        return f"CONTROL CHARACTER U+{code:04X}"


def zs_char_name(char):
    """Readable label for space separators."""
    try:
        return unicodedata.name(char)
    except ValueError:
        return f"SPACE SEPARATOR U+{ord(char):04X}"


def decode_unicode_tag(char):
    """Decode a Unicode tag character to its ASCII equivalent."""
    code = ord(char)
    if code == 0xE0001:
        return '[TAG_START]'
    elif code == 0xE007F:
        return '[TAG_END]'
    elif 0xE0020 <= code <= 0xE007E:
        # Map to ASCII space through tilde
        return chr(code - 0xE0000)
    else:
        return f'[TAG:{hex(code)}]'


def is_binary_file(file_path):
    """Check if a file is likely binary."""
    # First check by mime type
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type:
        if not mime_type.startswith('text/'):
            return True

    # Check by reading a chunk
    try:
        with open(file_path, 'rb') as f:
            chunk = f.read(8192)
            if b'\x00' in chunk:  # Null bytes indicate binary
                return True
    except:
        return True

    return False


def group_consecutive_chars(line_findings):
    """Group consecutive invisible characters together."""
    if not line_findings:
        return []

    # Sort by position
    sorted_findings = sorted(line_findings, key=lambda x: x['position'])

    grouped = []
    current_group = [sorted_findings[0]]

    for i in range(1, len(sorted_findings)):
        # Check if consecutive
        if sorted_findings[i]['position'] == current_group[-1]['position'] + 1:
            current_group.append(sorted_findings[i])
        else:
            # Save current group and start new one
            grouped.append(current_group)
            current_group = [sorted_findings[i]]

    # Don't forget the last group
    grouped.append(current_group)

    return grouped


def scan_file(file_path, include_cc=False, include_zs=False, include_confusable_spaces=False):
    """
    Scan a file for invisible unicode characters.
    Returns a list of findings.
    """
    findings = []

    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            for line_num, line in enumerate(f, 1):
                line_findings = []

                # Check for invisible characters
                for i, char in enumerate(line):
                    if char in INVISIBLE_CHARS:
                        line_findings.append({
                            'char': char,
                            'name': INVISIBLE_CHARS[char],
                            'position': i,
                            'type': 'invisible'
                        })
                    elif include_confusable_spaces and char in CONFUSABLE_SPACE_CHARS:
                        line_findings.append({
                            'char': char,
                            'name': CONFUSABLE_SPACE_CHARS[char],
                            'position': i,
                            'type': 'space_like'
                        })
                    elif is_variation_selector_supplement(char):
                        line_findings.append({
                            'char': char,
                            'name': variation_selector_name(char),
                            'position': i,
                            'type': 'invisible'
                        })
                    elif is_unicode_tag(char):
                        line_findings.append({
                            'char': char,
                            'name': 'UNICODE TAG',
                            'decoded': decode_unicode_tag(char),
                            'position': i,
                            'type': 'tag'
                        })
                    elif include_cc and unicodedata.category(char) == 'Cc' and char not in SKIP_CC_DEFAULT:
                        line_findings.append({
                            'char': char,
                            'name': control_char_name(char),
                            'position': i,
                            'type': 'cc'
                        })
                    elif include_zs and unicodedata.category(char) == 'Zs' and char not in SKIP_ZS_DEFAULT:
                        line_findings.append({
                            'char': char,
                            'name': zs_char_name(char),
                            'position': i,
                            'type': 'zs'
                        })

                if line_findings:
                    # Group consecutive characters
                    grouped_chars = group_consecutive_chars(line_findings)

                    findings.append({
                        'line_num': line_num,
                        'line': line,
                        'char_groups': grouped_chars  # Now contains groups of consecutive chars
                    })

    except Exception as e:
        return {'error': str(e)}

    return findings


def get_context_display(line, char_groups, context_chars=2, consecutive_threshold=10):
    """Generate a context display showing where invisible characters are."""
    result = []

    for group in char_groups:
        if len(group) == 1:
            # Single character
            finding = group[0]
            pos = finding['position']

            # Get context window
            start = max(0, pos - context_chars)
            end = min(len(line), pos + context_chars + 1)

            before = line[start:pos]
            char = finding['char']
            after = line[pos+1:end]

            # Build display
            context = before + 'â¦—' + char + 'â¦˜' + after
            context = context.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')

            char_display = f"{finding['name']} (0x{ord(char):04X})"
            if finding['type'] == 'tag':
                char_display += f" = '{finding['decoded']}'"

            result.append(f"    {char_display}")
            result.append(f"    Context: ...{context}...")
        else:
            # Consecutive group
            first_pos = group[0]['position']
            last_pos = group[-1]['position']

            # Get context window
            start = max(0, first_pos - context_chars)
            end = min(len(line), last_pos + context_chars + 1)

            before = line[start:first_pos]
            grouped_chars = ''.join(c['char'] for c in group)
            after = line[last_pos+1:end]

            # Build display
            context = before + 'â¦—' + grouped_chars + 'â¦˜' + after
            context = context.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')

            # Check if all are unicode tags
            all_tags = all(c['type'] == 'tag' for c in group)

            if all_tags:
                # Show decoded text for tag groups
                decoded_text = ''.join(c.get('decoded', '') for c in group)
                hex_range = f"0x{ord(group[0]['char']):04X}-0x{ord(group[-1]['char']):04X}"
                prefix = "âš  " if len(group) >= consecutive_threshold else ""
                result.append(
                    f"    {prefix}Consecutive UNICODE TAGS ({len(group)} chars, {hex_range}) = '{decoded_text}'"
                )
            else:
                # Mixed group - show each char
                char_list = []
                for c in group:
                    char_desc = f"{c['name']} (0x{ord(c['char']):04X})"
                    char_list.append(char_desc)
                prefix = "âš  " if len(group) >= consecutive_threshold else ""
                result.append(f"    {prefix}Consecutive group ({len(group)} chars): {', '.join(char_list)}")

            result.append(f"    Context: ...{context}...")

    return '\n'.join(result)


def calculate_suspicion_level(findings, consecutive_threshold=10):
    """
    Calculate suspicion level based on invisible code points found.

    Returns a dict with:
    - total_code_points: total count of invisible code points
    - unique_code_points: count of unique invisible characters
    - max_consecutive_code_points: largest consecutive run of invisible code points
    - max_consecutive_unicode_tags: largest consecutive run consisting only of Unicode tags
    - suspicion_level: info, low, high, or critical
    - reason: explanation of the assessment
    """
    # Count total code points
    total_code_points = 0
    unique_chars = set()
    max_consecutive_code_points = 0
    max_consecutive_unicode_tags = 0

    for finding in findings:
        for group in finding['char_groups']:
            total_code_points += len(group)
            max_consecutive_code_points = max(max_consecutive_code_points, len(group))
            if all(c['type'] == 'tag' for c in group):
                max_consecutive_unicode_tags = max(max_consecutive_unicode_tags, len(group))
            for char_info in group:
                unique_chars.add(char_info['char'])

    unique_code_points = len(unique_chars)

    # Determine suspicion level
    if total_code_points < 10:
        level = "info"
        reason = "Few code points"
    elif total_code_points < 50:
        level = "low"
        reason = "Some code points"
    elif total_code_points < 100:
        level = "high"
        reason = "Many code points"
    else:
        level = "critical"
        reason = "Excessive code points"

    # Escalate based on long consecutive runs of invisible code points.
    # Unicode-tag-only runs are additionally highlighted because they are
    # commonly used for hidden payload encoding.
    if max_consecutive_code_points >= consecutive_threshold:
        if level == "info":
            level = "low"
        reason = f"Long consecutive invisible run ({max_consecutive_code_points} code points)"
        if max_consecutive_unicode_tags >= consecutive_threshold:
            if level in ("info", "low"):
                level = "high"
            reason += f"; includes Unicode tag run ({max_consecutive_unicode_tags} tags)"

    return {
        'total_code_points': total_code_points,
        'unique_code_points': unique_code_points,
        'max_consecutive_code_points': max_consecutive_code_points,
        'max_consecutive_unicode_tags': max_consecutive_unicode_tags,
        'consecutive_threshold': consecutive_threshold,
        'suspicion_level': level,
        'reason': reason
    }


class DirectoryScanner:
    """Scanner that can stream results and track stats."""
    def __init__(
        self,
        target_dir,
        verbose=False,
        consecutive_threshold=10,
        include_cc=False,
        include_zs=False,
        include_confusable_spaces=False
    ):
        self.target_dir = Path(target_dir).resolve()
        self.verbose = verbose
        self.consecutive_threshold = consecutive_threshold
        self.include_cc = include_cc
        self.include_zs = include_zs
        self.include_confusable_spaces = include_confusable_spaces
        self.stats = {
            'files_scanned': 0,
            'files_with_findings': 0,
            'total_invisible_chars': 0,
            'skipped_binary': 0
        }
        self.results = {}

    def scan(self):
        """Generator that yields results as files are scanned."""
        for root, dirs, files in os.walk(self.target_dir):
            # Skip excluded directories
            dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]

            # Show current directory being scanned (in place, only if verbose)
            if self.verbose:
                rel_path = Path(root).relative_to(self.target_dir)
                display_path = str(rel_path) if str(rel_path) != '.' else '(root)'
                print(f"\rScanning: {display_path:<60}", end='', file=sys.stderr)

            for file in files:
                file_path = Path(root) / file

                # Skip binary files
                if is_binary_file(file_path):
                    self.stats['skipped_binary'] += 1
                    continue

                self.stats['files_scanned'] += 1

                findings = scan_file(
                    file_path,
                    include_cc=self.include_cc,
                    include_zs=self.include_zs,
                    include_confusable_spaces=self.include_confusable_spaces
                )

                if isinstance(findings, dict) and 'error' in findings:
                    continue

                if findings:
                    self.stats['files_with_findings'] += 1
                    # Count total invisible chars in this file
                    total_chars = sum(len(group) for f in findings for group in f['char_groups'])
                    self.stats['total_invisible_chars'] += total_chars

                    # Get file size
                    file_size = file_path.stat().st_size

                    # Calculate suspicion level
                    suspicion = calculate_suspicion_level(findings, consecutive_threshold=self.consecutive_threshold)

                    result = {
                        'file_path': str(file_path.relative_to(self.target_dir)),
                        'findings': findings,
                        'total_chars': total_chars,
                        'file_size': file_size,
                        'suspicion': suspicion
                    }

                    self.results[result['file_path']] = result
                    yield result


def scan_directory(
    target_dir,
    verbose=False,
    consecutive_threshold=10,
    include_cc=False,
    include_zs=False,
    include_confusable_spaces=False
):
    """Scan directory and return all results (backward compatibility)."""
    scanner = DirectoryScanner(
        target_dir,
        verbose,
        consecutive_threshold=consecutive_threshold,
        include_cc=include_cc,
        include_zs=include_zs,
        include_confusable_spaces=include_confusable_spaces
    )
    for _ in scanner.scan():
        pass  # Consume generator to populate results
    return scanner.results, scanner.stats


def summarize_chars(findings):
    """Return per-character counts sorted by frequency then name."""
    counts = defaultdict(int)
    for finding in findings:
        for group in finding['char_groups']:
            for char_info in group:
                counts[char_info['name']] += 1
    return sorted(counts.items(), key=lambda x: (-x[1], x[0]))


def build_file_report_rows(results):
    """Build compact one-row-per-file report data."""
    rows = []
    for file_path, data in sorted(results.items()):
        suspicion = data['suspicion']
        char_summary = summarize_chars(data['findings'])
        char_list = '; '.join(f"{name} ({count})" for name, count in char_summary)

        rows.append({
            'file_path': file_path,
            'file_size_bytes': data['file_size'],
            'suspicion_level': suspicion['suspicion_level'],
            'total_invisible_code_points': suspicion['total_code_points'],
            'unique_invisible_code_points': suspicion['unique_code_points'],
            'invisible_chars': char_list,
            'longest_consecutive_run': suspicion.get('max_consecutive_code_points', 0),
            'longest_unicode_tag_run': suspicion.get('max_consecutive_unicode_tags', 0),
            'notes': suspicion['reason']
        })
    return rows


def generate_report(results, stats, target_dir):
    """Generate a compact text report with one line per file."""
    lines = []
    lines.append("ASCII SMUGGLING DETECTION REPORT")
    lines.append(f"Target Directory: {target_dir}")
    lines.append(f"Files Scanned: {stats['files_scanned']}")
    lines.append(f"Binary Files Skipped: {stats['skipped_binary']}")

    if not results:
        lines.append("âœ“ No invisible unicode characters detected.")
        return '\n'.join(lines)

    lines.append(f"Files with Findings: {stats['files_with_findings']}")
    lines.append(f"Total Invisible Code Points: {stats['total_invisible_chars']}")
    lines.append("")
    lines.append(
        "file_path | total | unique | chars | longest_run | longest_tag_run | notes"
    )
    for row in build_file_report_rows(results):
        lines.append(
            f"{row['file_path']} | {row['total_invisible_code_points']} | "
            f"{row['unique_invisible_code_points']} | {row['invisible_chars']} | "
            f"{row['longest_consecutive_run']} | {row['longest_unicode_tag_run']} | {row['notes']}"
        )

    return '\n'.join(lines)


def generate_json_report(results, stats, target_dir):
    """Generate compact JSON format report (one object per file)."""

    report = {
        'metadata': {
            'target_directory': str(target_dir),
            'files_scanned': stats['files_scanned'],
            'binary_files_skipped': stats['skipped_binary'],
            'files_with_findings': stats['files_with_findings'],
            'total_invisible_code_points': stats['total_invisible_chars']
        },
        'files': build_file_report_rows(results)
    }

    return json.dumps(report, indent=2, ensure_ascii=False)


def generate_csv_report(results, stats, target_dir):
    """Generate compact CSV format report (one row per file)."""
    output = []

    # Header
    header = [
        'file_path',
        'file_size_bytes',
        'suspicion_level',
        'total_invisible_code_points',
        'unique_invisible_code_points',
        'invisible_chars',
        'longest_consecutive_run',
        'longest_unicode_tag_run',
        'notes'
    ]
    output.append(','.join(header))

    for row_data in build_file_report_rows(results):
        row = [
            row_data['file_path'],
            str(row_data['file_size_bytes']),
            row_data['suspicion_level'],
            str(row_data['total_invisible_code_points']),
            str(row_data['unique_invisible_code_points']),
            row_data['invisible_chars'],
            str(row_data['longest_consecutive_run']),
            str(row_data['longest_unicode_tag_run']),
            row_data['notes']
        ]

        escaped_row = []
        for field in row:
            if ',' in field or '"' in field or '\n' in field:
                field = '"' + field.replace('"', '""') + '"'
            escaped_row.append(field)

        output.append(','.join(escaped_row))

    return '\n'.join(output)


def write_csv_row(f, file_path, data):
    """Write a single compact CSV row for one file."""
    suspicion = data['suspicion']
    char_summary = summarize_chars(data['findings'])
    char_list = '; '.join(f"{name} ({count})" for name, count in char_summary)

    row = [
        file_path,
        str(data['file_size']),
        suspicion['suspicion_level'],
        str(suspicion['total_code_points']),
        str(suspicion['unique_code_points']),
        char_list,
        str(suspicion.get('max_consecutive_code_points', 0)),
        str(suspicion.get('max_consecutive_unicode_tags', 0)),
        suspicion['reason']
    ]

    escaped_row = []
    for field in row:
        if ',' in field or '"' in field or '\n' in field:
            field = '"' + field.replace('"', '""') + '"'
        escaped_row.append(field)

    f.write(','.join(escaped_row) + '\n')
    f.flush()


def main():
    parser = argparse.ArgumentParser(
        description='ASCII Smuggling Detection Tool - Scan files for invisible unicode characters'
    )
    parser.add_argument(
        '--target',
        required=True,
        help='Target directory to scan'
    )
    parser.add_argument(
        '--output',
        help='Output report file path (default: ./aid-report.<format>)'
    )
    parser.add_argument(
        '--format',
        choices=['text', 'json', 'csv'],
        default='csv',
        help='Output format: csv (default), json, or text'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Show progress while scanning'
    )
    parser.add_argument(
        '--stream',
        action='store_true',
        help='Print report to stdout instead of file'
    )
    parser.add_argument(
        '--consecutive-threshold',
        type=int,
        default=10,
        help='Escalate risk if there are this many consecutive invisible code points (default: 10)'
    )
    parser.add_argument(
        '--include-cc',
        action='store_true',
        help='Also scan for classic control characters (Unicode category Cc; excludes TAB/LF/CR)'
    )
    parser.add_argument(
        '--include-zs',
        action='store_true',
        help='Also scan for Unicode space separators (category Zs; excludes ASCII space U+0020)'
    )
    parser.add_argument(
        '--include-confusable-spaces',
        action='store_true',
        help='Also scan for confusable/suspicious spaces and fillers (for example U+00A0 NBSP)'
    )

    args = parser.parse_args()

    target_dir = Path(args.target)
    if not target_dir.exists():
        print(f"Error: Target directory '{target_dir}' does not exist.", file=sys.stderr)
        sys.exit(1)

    if not target_dir.is_dir():
        print(f"Error: Target '{target_dir}' is not a directory.", file=sys.stderr)
        sys.exit(1)

    if not args.verbose:
        print(f"Scanning {target_dir}...")

    if not args.stream and not args.output:
        extension_map = {'csv': 'csv', 'json': 'json', 'text': 'txt'}
        args.output = f"aid-report.{extension_map[args.format]}"

    # Track if we're using streaming mode
    streaming_mode = not args.stream and args.format == 'csv'

    # Streaming mode - write to file incrementally (CSV only for now)
    if streaming_mode:
        # Open file for streaming CSV output
        output_path = Path(args.output)
        with open(output_path, 'w', encoding='utf-8') as f:
            # Write CSV header
            header = [
                'file_path', 'file_size_bytes', 'suspicion_level',
                'total_invisible_code_points', 'unique_invisible_code_points',
                'invisible_chars', 'longest_consecutive_run',
                'longest_unicode_tag_run', 'notes'
            ]
            f.write(','.join(header) + '\n')
            f.flush()

            # Stream results as they're found
            scanner = DirectoryScanner(
                target_dir,
                verbose=args.verbose,
                consecutive_threshold=args.consecutive_threshold,
                include_cc=args.include_cc,
                include_zs=args.include_zs,
                include_confusable_spaces=args.include_confusable_spaces
            )
            for result in scanner.scan():
                write_csv_row(f, result['file_path'], result)

        results = scanner.results
        stats = scanner.stats

        if args.verbose:
            print("\r" + " " * 80 + "\r", end='', file=sys.stderr)  # Clear progress line

    else:
        # Buffer mode - for --stream or non-CSV formats
        results, stats = scan_directory(
            target_dir,
            verbose=args.verbose,
            consecutive_threshold=args.consecutive_threshold,
            include_cc=args.include_cc,
            include_zs=args.include_zs,
            include_confusable_spaces=args.include_confusable_spaces
        )

        if args.verbose:
            print("\r" + " " * 80 + "\r", end='', file=sys.stderr)  # Clear progress line

        if not args.stream:
            print(f"Generating {args.format} report...")

        # Generate report in requested format
        if args.format == 'json':
            report = generate_json_report(results, stats, target_dir)
        elif args.format == 'csv':
            report = generate_csv_report(results, stats, target_dir)
        else:  # text
            report = generate_report(results, stats, target_dir)

    # Calculate suspicion level breakdown
    suspicion_counts = {'info': 0, 'low': 0, 'high': 0, 'critical': 0}

    # Calculate character category breakdown
    category_counts = {
        'Unicode Tags': 0,
        'Zero-Width And Joiners': 0,
        'Directional And Bidi Marks': 0,
        'Variation Selectors': 0
    }
    category_counts['Invisible Operators'] = 0
    category_counts['Deprecated Format Controls'] = 0
    category_counts['Space-Like Or Blank Chars'] = 0
    category_counts['Control Characters (Cc)'] = 0
    category_counts['Space Separators (Zs)'] = 0
    category_counts['Other Invisible'] = 0

    if results:
        for data in results.values():
            level = data['suspicion']['suspicion_level']
            suspicion_counts[level] += 1

            # Count by category
            for finding in data['findings']:
                for group in finding['char_groups']:
                    for char_info in group:
                        char = char_info['char']
                        if char_info['type'] == 'tag':
                            category_counts['Unicode Tags'] += 1
                        elif char in ZERO_WIDTH_CHARS:
                            category_counts['Zero-Width And Joiners'] += 1
                        elif char in DIRECTIONAL_MARKS:
                            category_counts['Directional And Bidi Marks'] += 1
                        elif char in VARIATION_SELECTORS_BASIC or is_variation_selector_supplement(char):
                            category_counts['Variation Selectors'] += 1
                        elif char in INVISIBLE_OPERATORS:
                            category_counts['Invisible Operators'] += 1
                        elif char in DEPRECATED_FORMAT_CONTROLS:
                            category_counts['Deprecated Format Controls'] += 1
                        elif char_info.get('type') == 'space_like':
                            category_counts['Space-Like Or Blank Chars'] += 1
                        elif char_info.get('type') == 'cc':
                            category_counts['Control Characters (Cc)'] += 1
                        elif char_info.get('type') == 'zs':
                            category_counts['Space Separators (Zs)'] += 1
                        else:
                            category_counts['Other Invisible'] += 1

    # Write report or stream to stdout (only if not already written in streaming mode)
    if not streaming_mode:
        if args.stream:
            # Print to stdout
            try:
                print(report)
            except BrokenPipeError:
                # Allow piping to commands like `head` without a traceback.
                return
        else:
            # Write to file
            output_path = Path(args.output)
            output_path.write_text(report, encoding='utf-8')

    # Show summary stats
    if not args.stream:
        print(f"  Files scanned: {stats['files_scanned']}")
        if stats['files_with_findings'] > 0:
            print(f"  âš  Files with findings: {stats['files_with_findings']}")
            if suspicion_counts['info'] > 0:
                print(f"    ðŸ”µ Info: {suspicion_counts['info']}")
            if suspicion_counts['low'] > 0:
                print(f"    ðŸŸ¢ Low: {suspicion_counts['low']}")
            if suspicion_counts['high'] > 0:
                print(f"    ðŸŸ  High: {suspicion_counts['high']}")
            if suspicion_counts['critical'] > 0:
                print(f"    ðŸ”´ Critical: {suspicion_counts['critical']}")
            print(f"  âš  Total invisible code points: {stats['total_invisible_chars']}")

            # Show category breakdown
            print(f"  ðŸ“Š By category:")
            for category_name, count in category_counts.items():
                if count > 0:
                    print(f"    {category_name}: {count}")
            print(f"  â„¹ Consecutive threshold: {args.consecutive_threshold}")
            if args.include_cc:
                print(f"  â„¹ Extra scan enabled: Cc control chars (excluding TAB/LF/CR)")
            if args.include_zs:
                print(f"  â„¹ Extra scan enabled: Zs space separators (excluding U+0020 SPACE)")
            if args.include_confusable_spaces:
                print(f"  â„¹ Extra scan enabled: confusable/suspicious spaces and fillers")
            print(f"  â„¹ Reminder: Manually inspect flagged files to verify intent/context.")
        else:
            print(f"  âœ“ No invisible code points found")

        if streaming_mode:
            print(f"âœ“ Report written to {output_path}")
        else:
            print(f"âœ“ Report written to {Path(args.output)}")


if __name__ == '__main__':
    main()
